import json
import os
import requests
import chromadb
import uvicorn
from fastapi import FastAPI, HTTPException, Request
import openai  # PÅ™idÃ¡me OpenAI import
from starlette.responses import JSONResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager

# NaÄtenÃ­ API klÃ­Äe z prostÅ™edÃ­
openai.api_key = os.getenv("OPENAI_API_KEY")  # ZÃ­skÃ¡me API klÃ­Ä z prostÅ™edÃ­

# URL k souboru s embeddingy na GitHubu (RAW verze!)
GITHUB_EMBEDDINGS_URL = "https://raw.githubusercontent.com/Dahor212/fastapi-chatbot/main/data/embeddings.json"

# Inicializace Chroma
chroma_client = chromadb.PersistentClient(path="./chroma_db")
collection = chroma_client.get_or_create_collection(name="documents")

# NaÄtenÃ­ embeddingÅ¯ z GitHubu
def load_embeddings_from_github():
    try:
        response = requests.get(GITHUB_EMBEDDINGS_URL)
        response.raise_for_status()
        embeddings_data = response.json()
        print("âœ… Embeddingy ÃºspÄ›Å¡nÄ› naÄteny z GitHubu!")
        return embeddings_data
    except requests.exceptions.RequestException as e:
        print(f"âŒ Chyba pÅ™i naÄÃ­tÃ¡nÃ­ embeddingÅ¯ z GitHubu: {e}")
        return None

@asynccontextmanager
async def lifespan(app: FastAPI):
    print("ğŸ“¥ NaÄÃ­tÃ¡m embeddingy z GitHubu...")
    embeddings = load_embeddings_from_github()

    if embeddings:
        existing_ids = collection.get()["ids"]
        if existing_ids:
            collection.delete(ids=existing_ids)  # SprÃ¡vnÃ© mazÃ¡nÃ­ celÃ© kolekce
        for doc_id, data in embeddings.items():
            if "embedding" in data:
                collection.add(ids=[doc_id], embeddings=[data["embedding"]])
        print("âœ… Embeddingy ÃºspÄ›Å¡nÄ› uloÅ¾eny do ChromaDB!")

    yield
    print("ğŸ›‘ Aplikace se ukonÄuje.")

app = FastAPI(lifespan=lifespan)

# PÅ™idÃ¡nÃ­ CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # PovolÃ­ vÅ¡echny domÃ©ny
    allow_credentials=True,
    allow_methods=["*"],  # PovolÃ­ vÅ¡echny metody
    allow_headers=["*"],  # PovolÃ­ vÅ¡echny hlaviÄky
)

# ZÃ¡kladnÃ­ route pro /
@app.get("/")
async def root():
    return {"message": "Hello, world!"}

# Route pro favicon.ico
@app.get("/favicon.ico")
async def favicon():
    return JSONResponse(content={}, status_code=204)  # VrÃ¡tÃ­ prÃ¡zdnou odpovÄ›Ä

@app.post("/chat")
async def chat(request: Request):
    data = await request.json()
    query = data.get("query")
    
    if not query:
        raise HTTPException(status_code=400, detail="Query is required")

    try:
        # GenerovÃ¡nÃ­ embeddingu pro dotaz
        query_embedding = openai.Embedding.create(input=query, model="text-embedding-ada-002")["data"][0]["embedding"]
    except openai.error.OpenAIError as e:
        print(f"âŒ Chyba pÅ™i pÅ™ipojenÃ­ k OpenAI API: {e}")
        raise HTTPException(status_code=500, detail="Error connecting to OpenAI API")

    # HledÃ¡nÃ­ v ChromaDB
    results = collection.query(query_embeddings=[query_embedding], n_results=1)

    if results["documents"]:
        # MÃ­sto odesÃ­lÃ¡nÃ­ celÃ© odpovÄ›di najednou, pouÅ¾ij StreamingResponse
        def generate():
            for doc in results["documents"]:
                yield doc  # PostupnÄ› posÃ­lej obsah odpovÄ›di

        return StreamingResponse(generate(), media_type="text/plain")
    else:
        return JSONResponse(content={"message": "Answer not found in the database."}, status_code=404)

if __name__ == "__main__":
    # ZÃ­skej port z prostÅ™edÃ­, nebo pouÅ¾ij 8000 jako fallback
    port = int(os.getenv("PORT", 8000))
    uvicorn.run("main:app", host="0.0.0.0", port=port)
